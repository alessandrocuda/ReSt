{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tokenizer import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "import wordninja\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import ast\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import emoji\n",
    "import unicodedata\n",
    "\n",
    "import gzip\n",
    "\n",
    "import spacy_udpipe\n",
    "import spacy\n",
    "import language_tool_python\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded a model for the 'it' language\n"
     ]
    }
   ],
   "source": [
    "#Udpipe\n",
    "spacy_udpipe.download(\"it\")\n",
    "nlp = spacy_udpipe.load(\"it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of files to read from\n",
    "train_val_AB_TSV = '../../../SaRaH/dataset/haspeede2/raw/haspeede2_dev/haspeede2_dev_taskAB.tsv'\n",
    "\n",
    "italian_words = '../../../SaRaH/dataset/words/parole_uniche.txt'\n",
    "italian_gzip = '../../../SaRaH/dataset/words/italian_words.txt.gz'\n",
    "bad_words = '../../../SaRaH/dataset/words/lista_badwords.txt'\n",
    "\n",
    "test_tweets_AB_TSV = '../../../SaRaH/dataset/haspeede2/raw/haspeede2_test/haspeede2_test_taskAB-tweets.tsv'\n",
    "test_news_AB_TSV = '../../../SaRaH/dataset/haspeede2/raw/haspeede2_test/haspeede2-test_taskAB-news.tsv'\n",
    "\n",
    "reference_tweets_AB_TSV = '../../../SaRaH/dataset/haspeede2/raw/haspeede2_reference/haspeede2_reference_taskAB-tweets.tsv'\n",
    "reference_news_AB_TSV = '../../../SaRaH/dataset/haspeede2/raw/haspeede2_reference/haspeede2_reference_taskAB-news.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wordninja\n",
    "lm = wordninja.LanguageModel(italian_gzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Italian dictionary\n",
    "f1 = open(italian_words, 'r', encoding='utf8')\n",
    "\n",
    "italian_dict = [] #list of lowercase words\n",
    "\n",
    "for x in f1:\n",
    "    y = x.rstrip()\n",
    "    y = y.lower()\n",
    "    if y != '':\n",
    "        italian_dict.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad Words\n",
    "f2 = open(bad_words, 'r', encoding='utf8')\n",
    "\n",
    "bad_words_dict = [] #list of lowercase words\n",
    "\n",
    "for x in f2:\n",
    "    y = x.rstrip()\n",
    "    y = y.lower()\n",
    "    if y != '':\n",
    "        bad_words_dict.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "df = pd.read_csv(train_val_AB_TSV, sep='\\t')\n",
    "df1 = pd.read_csv(train_val_AB_TSV, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"text \": \"text\"}, inplace=True) #the text column is identified by 'text ' (with a space at the end), change\n",
    "df1.rename(columns={\"text \": \"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hs</th>\n",
       "      <th>stereotype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2066</td>\n",
       "      <td>È terrorismo anche questo, per mettere in uno stato di soggezione le persone e renderle innocue, mentre qualcuno... URL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2045</td>\n",
       "      <td>@user @user infatti finché ci hanno guadagnato con i campi #rom tutto era ok con #Alemanno #Ipocriti</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>Corriere: Tangenti, Mafia Capitale dimenticataMazzette su buche e campi rom URL #roma</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1259</td>\n",
       "      <td>@user ad uno ad uno, perché quando i migranti israeliti arrivarono in terra di Canaan fecero fuori tutti i Canaaniti.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>949</td>\n",
       "      <td>Il divertimento del giorno? Trovare i patrioti italiani che inneggiano contro i rom facendo la spesa alla #Lidl (multinazionale tedesca).</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6832</th>\n",
       "      <td>9340</td>\n",
       "      <td>Gli stati nazionali devono essere pronti a rinunciare alla propria sovranità. Lo ha detto la Merkel , che ha aggiunto che gli stati nazionali non devono ascoltare la volontà dei loro cittadini quando si tratta di questioni che riguardano immigrazione, confini, o persino sovranità URL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6833</th>\n",
       "      <td>9121</td>\n",
       "      <td>Il ministro dell'interno della Germania #HorstSeehofer,sta facendo la proposta di dare soldi agli immigrati che vogliono tornare a casa e aiutarli a creare un'attività a casa loro e fare business con la Germania.Chi paga?Una parte i crucchi e il resto l'Europa, cioè io e voi!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>8549</td>\n",
       "      <td>#Salvini: In Italia troppi si sono montati la testa, io ringrazio Dio e voi per questi mesi straordinari. Vi raccontavano che su immigrazione non si poteva fare nulla, è bastato usare buonsenso e coraggio. #iocisono #piazzadelpopolo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>9240</td>\n",
       "      <td>@user @user Chi giubila in buona fede non ha capito niente. Purtroppo credo che i più non siano in buona fede. I migranti sono un grosso business e chi finora li ha voluti non vuole perdere questo guadagno</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>8000</td>\n",
       "      <td>I giovani cristiani in #Etiopia sono indotti dagli islamisti a convertirsi all'Islam con promesse di lavoro, istruzione e aiuti abitativi. Alcune miniere impiegano solo musulmani. Lo riferisce ad ACS un leader cristiano locale, anonimo per motivi di sicurezza. Preghiamo per loro! URL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6837 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0     2066   \n",
       "1     2045   \n",
       "2       61   \n",
       "3     1259   \n",
       "4      949   \n",
       "...    ...   \n",
       "6832  9340   \n",
       "6833  9121   \n",
       "6834  8549   \n",
       "6835  9240   \n",
       "6836  8000   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                               text  \\\n",
       "0                                                                                                                                                                          È terrorismo anche questo, per mettere in uno stato di soggezione le persone e renderle innocue, mentre qualcuno... URL    \n",
       "1                                                                                                                                                                                             @user @user infatti finché ci hanno guadagnato con i campi #rom tutto era ok con #Alemanno #Ipocriti    \n",
       "2                                                                                                                                                                                                            Corriere: Tangenti, Mafia Capitale dimenticataMazzette su buche e campi rom URL #roma    \n",
       "3                                                                                                                                                                            @user ad uno ad uno, perché quando i migranti israeliti arrivarono in terra di Canaan fecero fuori tutti i Canaaniti.    \n",
       "4                                                                                                                                                        Il divertimento del giorno? Trovare i patrioti italiani che inneggiano contro i rom facendo la spesa alla #Lidl (multinazionale tedesca).    \n",
       "...                                                                                                                                                                                                                                                                                             ...   \n",
       "6832  Gli stati nazionali devono essere pronti a rinunciare alla propria sovranità. Lo ha detto la Merkel , che ha aggiunto che gli stati nazionali non devono ascoltare la volontà dei loro cittadini quando si tratta di questioni che riguardano immigrazione, confini, o persino sovranità URL    \n",
       "6833          Il ministro dell'interno della Germania #HorstSeehofer,sta facendo la proposta di dare soldi agli immigrati che vogliono tornare a casa e aiutarli a creare un'attività a casa loro e fare business con la Germania.Chi paga?Una parte i crucchi e il resto l'Europa, cioè io e voi!    \n",
       "6834                                                      #Salvini: In Italia troppi si sono montati la testa, io ringrazio Dio e voi per questi mesi straordinari. Vi raccontavano che su immigrazione non si poteva fare nulla, è bastato usare buonsenso e coraggio. #iocisono #piazzadelpopolo    \n",
       "6835                                                                                 @user @user Chi giubila in buona fede non ha capito niente. Purtroppo credo che i più non siano in buona fede. I migranti sono un grosso business e chi finora li ha voluti non vuole perdere questo guadagno    \n",
       "6836  I giovani cristiani in #Etiopia sono indotti dagli islamisti a convertirsi all'Islam con promesse di lavoro, istruzione e aiuti abitativi. Alcune miniere impiegano solo musulmani. Lo riferisce ad ACS un leader cristiano locale, anonimo per motivi di sicurezza. Preghiamo per loro! URL    \n",
       "\n",
       "      hs  stereotype  \n",
       "0      0           0  \n",
       "1      0           0  \n",
       "2      0           0  \n",
       "3      0           0  \n",
       "4      0           0  \n",
       "...   ..         ...  \n",
       "6832   0           0  \n",
       "6833   0           0  \n",
       "6834   0           0  \n",
       "6835   0           0  \n",
       "6836   0           1  \n",
       "\n",
       "[6837 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Removing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url(text):\n",
    "    return re.sub(r'URL', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_url)\n",
    "df1['text'] = df['text'].apply(clean_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Removing Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tag(text):\n",
    "    return re.sub(r'@user', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_tag)\n",
    "df1['text'] = df['text'].apply(clean_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature extraction: length of the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_length(text):\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_length'] = df['text'].apply(text_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Normalizing emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giulia\\Anaconda3\\lib\\site-packages\\ekphrasis\\classes\\tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading english - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giulia\\Anaconda3\\lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/cbaziotis/ekphrasis\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    #unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=False).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_emoticon(text):\n",
    "    return \" \".join(text_processor.pre_process_doc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(normalize_emoticon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Converting ':' into 'double_dots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_double_dots(text):\n",
    "    return re.sub(r':', ' double_dots ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(convert_double_dots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Translation of emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_emoticon(text):\n",
    "    text_result = emoji.demojize(text, language='it')\n",
    "    return text_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(translate_emoticon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Removing : (especially from emoji translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_two_dots(text):\n",
    "    return re.sub(r':', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_two_dots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Converting 'double_dots' into ':'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconvert_double_dots(text):\n",
    "    return re.sub(r'double_dots', ' : ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(reconvert_double_dots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Add space before #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_space_before_hashtag(text): ##io#vado -> # #io #vado\n",
    "    words = text.split()\n",
    "    newwords = []\n",
    "    for word in words:\n",
    "        for i in range(0, len(word)):\n",
    "            if i != 0:\n",
    "                if word[i] == '#':\n",
    "                    word = add_space_before_hashtag(word[:i]) + ' ' + add_space_before_hashtag(word[i:])\n",
    "        newwords.append(word)\n",
    "    return ' '.join(newwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(add_space_before_hashtag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature extraction: number of hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hashtags(text):\n",
    "    result = re.findall(r'#\\S+', text)\n",
    "    return len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hashtags'] = df['text'].apply(find_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_hashtags(text):\n",
    "    return re.sub(r'#\\S+', '#hashtag', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'] = df1['text'].apply(normalize_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Replacing hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_words = ['lidl', 'roma', 'caritas', 'syria', 'isis', 'm5s', 'apatridi', 'brexit', 'sinta', 'msna', 'yacme',\n",
    "                 'ckan', 'dimartedi', 'karak', 'cojoni', 'uae', 'scampia', 'onsci', 'hamas', 'ncd', 'olbes', 'fdian',\n",
    "                 'acquarius', 'aquarius', 'macron', 'barbarians', 'kyenge', 'kienge', 'mef', 'muslim', 'error', 'soros',\n",
    "                 'italexit', 'sprar', 'ahvaz', 'nsa', 'enez', 'daspo', 'cpr', 'desire', 'boldrina', 'msf', 'belgium',\n",
    "                 'piddino', 'piddina', 'fdi', 'zarzis', 'eliminiamolo', 'strasbourg', 'isee', 'sophia', 'unit', 'oeshh',\n",
    "                 'porrajmos', 'dibba', 'ciociaria', 'cie', 'junker', 'is', 'syriza', 'linate', 'raqqa', 'ama', 'cesedi',\n",
    "                 'aicds', 'heidelberg', 'ffoo', 'cvd', 'forex', 'docufilm', 'reyn', 'hooligans', 'anpal', 'rdc', 'rohingya',\n",
    "                 'nwo', 'def', 'cattivisti', 'vauro', 'sorosiane', 'libya', 'censis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_space(text):\n",
    "    words = text.split()\n",
    "    newwords = []\n",
    "    for word in words:\n",
    "        for i in range(0, len(word)):\n",
    "            if i != len(word)-1 and word[i] != ' ':\n",
    "                if word[i].islower() and word[i+1].isupper():\n",
    "                    word = word[:i+1] + ' ' + word[i+1:]\n",
    "        newwords.append(word)\n",
    "    return ' '.join(newwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_hashtags(text):\n",
    "    \n",
    "    text = ' ' + text + ' '\n",
    "    result = re.findall(r'#\\S+', text)\n",
    "    \n",
    "    for word in result:\n",
    "        new_word = '< '\n",
    "        if word[1:].lower() not in hashtag_words:\n",
    "            spaced_word = add_space(word)\n",
    "            splitted = lm.split(spaced_word)\n",
    "            \n",
    "            for i in range(0, len(splitted)):\n",
    "                if i == 0:\n",
    "                    new_word = new_word + splitted[i]\n",
    "                else:\n",
    "                    new_word = new_word + ' ' + splitted[i]\n",
    "        else:\n",
    "            new_word = new_word + word[1:]\n",
    "        new_word = new_word + ' >'\n",
    "        \n",
    "        text = text.replace(word, new_word)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(replace_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Fixing Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_hashtags = {'je sui s Charlie':'je suis Charlie', 'libere t cogita n s':'libere t cogitans', 'm a g g i o':'maggio', \n",
    "                  'ha te speech':'hate speech', 'w ed din g tour i sm':'wedding tourism', 'in comin g':'incoming',\n",
    "                  'dimarte d':'dimarted', 'dall a vostra':'dalla vostra', 'Trattati Rom a':'Trattati Roma',\n",
    "                  'I u venta':'Iuventa', 'Woolf e':'Woolfe', 'Attuali t':'Attualit', 'Morni ng':'Morning',\n",
    "                  'Fort Lau derda l e':'Fort Lauderdale', 'mi gran ts':'migrants', 'a p r i l e':'aprile',\n",
    "                  'E n e r g y':'Energy', 'I g les':'Igles', 'Christ mas':'Christmas', 'Sud Tiro l':'Sud Tirol',\n",
    "                  'Paler m':'Palerm', 'esma red ze po va':'esma redzepova', 'gip sy':'gipsy', 'auster it':'austerit',\n",
    "                  'immigrati on ban':'immigration ban', 'Financial Time s':'Financial Times', 'metro rom a':'metro roma',\n",
    "                  'Su ed deutsch e Ze i tung':'Sueddeutsche Zeitung', 'porta aporta':'porta a porta', 'terro r':'terror',\n",
    "                  'immi gran ts':'immigrants', 'giornata dell a memoria':'giornata della memoria', 'm a r z o':'marzo',\n",
    "                  'dusse l dor f':'dusseldorf', 'riscopriamo l i':'riscopriamoli', 'ultimo ra':'ultima ora',\n",
    "                  'Cercate l i':'Cercateli', 'Islam op ho bia':'Islamophobia', 'd i c e m b r e':'dicembre',\n",
    "                  'g e n n a i o':'gennaio', 'f e b b r a i o':'febbraio', 'g i u g n o':'giugno', 'l u g l i o':'luglio',\n",
    "                  'a g o s t o':'agosto', 's e t t e m b r e':'settembre', 'o t t o b r e':'ottobre',\n",
    "                  'n o v e m b r e':'novembre', 'ta gad al a 7':'tagada la 7', 'Coffe e break l a 7':'Coffee break la 7',\n",
    "                  'A S Rom a':'Associazione Sportiva Roma', 'Stadio Dell a Rom a':'Stadio Della Roma',\n",
    "                  'best songo f movie':'best song of movie', 'un avita in metro':'una vita in metro', 'l e iene':'le iene',\n",
    "                  'l a zanzara':'la zanzara', 'charlie h e b do':'charlie hebdo', 'Loo king':'Looking',\n",
    "                  'Rom a Non Alza Muri':'Roma Non Alza Muri', 'r e fu gee s':'refugees', 'non una dime mo':'non una di meno',\n",
    "                  'i t a l i a':'italia', 'r ss':'rss', 'at tack':'attack', 'a t t u a l i t a':'attualità',\n",
    "                  'no tengo din ero':'no tengo dinero', 'Hi jr i':'Hijri', 'Asl i Erdogan':'Asli Erdogan',\n",
    "                  'i si s fu c k you':'isis fuck you', 'L a Ru spetta':'La Ruspetta', 'Go o g l e Aler ts':'Google Alerts',\n",
    "                  'A mi s':'Amis', 'Bal on Mundial':'Balon Mundial', 'l i dl':'lidl', 'racis m':'racism ',\n",
    "                  'C y ber':'Cyber', 'Sili con Valle y':'Silicon Valley', 'Medio Campi dan':'Medio Campidan',\n",
    "                  'w e l comere fu gee s':'welcome refugees', 'Ta gada':'Tagada', 'Grande sy n the':'Grande synthe',\n",
    "                  'contentivo i':'contenti voi', 'at tack s':'attacks', 'REY N':'REYN', 'Marine L e Pen':'Marine Le Pen',\n",
    "                  't ru e story':'true story', 'brex it':'brexit', 'delledonne':'delle donne', 'fu c kis i s':'fuck isis',\n",
    "                  'islam i s the pro ble m':'islam is the problem', 'l a gabbia':'la gabbia', 'fu c k islam':'fuck islam',\n",
    "                  'fu c k':'fuck', 'fu c k musli ms':'fuck muslims', 'sapeva telo':'sapevatelo', 'R in y':'Riny',\n",
    "                  'A f g han Con f':'Afghan Con f', 'Ch al i e H e b do':'Chelie Hebdo', 's k y':'sky', 'H e b do':'Hebdo',\n",
    "                  'S ho ot in g':'Shooting', 'Islam i c State':'Islamic State', 'l a 7':'la 7', 'Daisy Os akue':'Daisy Osakue',\n",
    "                  'laria che tira':'l aria che tira', 'i phon e X S max':'iphone XSmax', 'L e Ga':'lega',\n",
    "                  'laria che tirala':'l aria che tira la', 'Casa po un d':'Casa pound', 'R M C NEWS':'RMC NEWS',\n",
    "                  'm i l i o n i':'milioni', 'un altro cucchia in odi merda':'un altro cucchiaino di merda',\n",
    "                  'omnibus l a 7':'omnibus la 7', 'job sa c t':'jobs act', 'Mi grati on':'Migration',\n",
    "                  'Movi men t Onesti':'Moviment Onesti', 'none larena':'non è l arena' ,'Non Un ad i Meno':'Non Una di Meno',\n",
    "                  'Fil c ams Collettiva':'Filcams Collettiva', 'Time s':'Times', 'ci vi l t allo sbando':'civiltà allo sbando',\n",
    "                  'Am ne st y International':'Amnesty International', 'C H I U D E T E':'CHIUDETE', 'Open Arm s':'Open Arms',\n",
    "                  'Gilet s J a un e s':'Gilets Jaunes', 'Mi grant I':'MigrantI', 'Horst Se e hofer':'Horst Seehofer',\n",
    "                  '5s':'cinque stelle', 'rd c':'rdc', 'piazza delpopolo':'piazza del popolo'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_fix(text):\n",
    "    for word in fixed_hashtags:\n",
    "        #text = text.replace(word, fixed_hashtags[word])\n",
    "        text = re.sub(re.escape(word), fixed_hashtags[word], text, flags=re.IGNORECASE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(hashtag_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Normalizing Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numbers(text):\n",
    "    try:\n",
    "        val = int(text)\n",
    "    except:\n",
    "        text = re.sub('\\d', '@Dg', text)\n",
    "        return text\n",
    "    if val >= 0 and val < 2100:\n",
    "        return str(val)\n",
    "    else:\n",
    "        return \"DIGLEN_\" + str(len(str(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(normalize_numbers)\n",
    "df1['text'] = df['text'].apply(normalize_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Removing _, \\\\n, \\\\ and /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_some_punctuation(text):\n",
    "    text = ' ' + text + ' '\n",
    "    text = re.sub(r'\\\\n', '. ', text)\n",
    "    text = re.sub(r'\\\\', ' ', text)\n",
    "    text = re.sub(r'/', ' ', text)\n",
    "    return re.sub(r'_', ' ', text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(normalize_numbers)\n",
    "df1['text'] = df['text'].apply(normalize_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Add space between lowercase and uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_space(text):\n",
    "    words = text.split()\n",
    "    newwords = []\n",
    "    for word in words:\n",
    "        for i in range(0, len(word)):\n",
    "            if i != len(word)-1 and word[i] != ' ':\n",
    "                if word[i].islower() and word[i+1].isupper():\n",
    "                    word = word[:i+1] + ' ' + word[i+1:]\n",
    "        newwords.append(word)\n",
    "    return ' '.join(newwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(add_space)\n",
    "df1['text'] = df1['text'].apply(add_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Convert all emoticons written in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_text = {\n",
    "    '<kiss>': 'bacio',\n",
    "    '<happy>': 'felice',\n",
    "    '<laugh>': 'risata',\n",
    "    '<sad>': 'triste',\n",
    "    '<surprise>': 'sorpreso',\n",
    "    '<wink>': 'occhiolino',\n",
    "    '<tong>': 'faccia con lingua',\n",
    "    '<annoyed>': 'annoiato',\n",
    "    '<seallips>': 'labbra sigillate',\n",
    "    '<angel>': 'angelo',\n",
    "    '<devil>': 'diavolo',\n",
    "    '<highfive>' : 'batti il cinque',\n",
    "    '<heart>': 'cuore',\n",
    "    '<user>' : 'persona',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_emoticon_text(text):\n",
    "    text_words = text.split()\n",
    "    new_words  = [emoticons_text.get(ele, ele) for ele in text_words]\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_emoticon_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature extraction: percentage of words written in CAPS-LOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caps_lock_words(text):\n",
    "    words = text.split()\n",
    "    count_caps_lock = 0\n",
    "    number_of_words = len(words)\n",
    "    \n",
    "    for word in words:\n",
    "        if word.isupper() == True:\n",
    "            count_caps_lock = count_caps_lock + 1\n",
    "            \n",
    "    return ((count_caps_lock*100)//number_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['%CAPS-LOCK words'] = df['text'].apply(caps_lock_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Normalizing Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    words = text.split()\n",
    "    result_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) > 26:\n",
    "            return \"__LONG-LONG__\"\n",
    "        new_word = normalize_numbers(word)\n",
    "        if new_word != word:\n",
    "            word = new_word\n",
    "        if word[0].isupper():\n",
    "            word = word.capitalize()\n",
    "        else:\n",
    "            word = word.lower()\n",
    "        result_words.append(word)\n",
    "        \n",
    "    return ' '.join(result_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(normalize_text)\n",
    "df1['text'] = df['text'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature extraction: number of ‘!’ inside the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esclamations(text):\n",
    "    return text.count('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['esclamations'] = df['text'].apply(esclamations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature extraction: number of ‘?’ inside the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def questions(text):\n",
    "    return text.count('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['questions'] = df['text'].apply(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cleaning Censured Bad Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_censured_bad_words(text):\n",
    "    text = \" \" + text + \" \"\n",
    "    text = re.sub(r' c[.x*@%#$^]+i ', ' coglioni ', text)\n",
    "    text = re.sub(r' c[.x*@%#$^]+e ', ' coglione ', text)\n",
    "    text = re.sub(r' c[.x*@%#$^]+o ', ' cazzo ', text) \n",
    "    text = re.sub(r' c[.x*@%#$^]+i ', ' cazzi ', text) \n",
    "    text = re.sub(r' m[.x*@%#$^]+a ', ' merda ', text) \n",
    "    text = re.sub(r' m[.x*@%#$^]+e ', ' merde ', text) \n",
    "    text = re.sub(r' c[.x*@%#$^]+ulo ', ' culo ', text) \n",
    "    text = re.sub(r' p[.x*@%#$^]+a ', ' puttana ', text)\n",
    "    text = re.sub(r' p[.x*@%#$^]+e ', ' puttane ', text)\n",
    "    text = re.sub(r' t[.x*@%#$^]+a ', ' troia ', text)\n",
    "    text = re.sub(r' t[.x*@%#$^]+e ', ' troie ', text)\n",
    "    text = re.sub(r' s[.x*@%#$^]+o ', ' stronzo ', text)\n",
    "    text = re.sub(r' s[.x*@%#$^]+i ', ' stronzi ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_censured_bad_words)\n",
    "df1['text'] = df1['text'].apply(clean_censured_bad_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Removing #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hashtag_symbol(text):\n",
    "    text = ' ' + text + ' '\n",
    "    return re.sub(r'#', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_hashtag_symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Removing laughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "laughs = ['ah', 'eh', 'he' 'ih', 'hi'] #non elimina ahahahah, ma solo ah\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "\n",
    "def clean_laughs(text):\n",
    "    #s = \"ahahahah ho fame io, eh eh\" -> \" ho fame io,\"\n",
    "    text_words = text.split()\n",
    "    new_words  = [word for word in text_words if word.lower() not in laughs]\n",
    "    \n",
    "    new_text = ' '.join(new_words)\n",
    "    \n",
    "    for i in new_words:\n",
    "        j = i.lower()\n",
    "        for k in vowels:\n",
    "            if ('h' in j) and (len(j) >= 4):\n",
    "                if (len(j) - 2) <= (j.count(k) + j.count('h')):\n",
    "                    new_text = new_text.replace(i, '')\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_laughs)\n",
    "df1['text'] = df1['text'].apply(clean_laughs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Removing nearby equal vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_words_vowels = ['coop', 'facebook', 'canaan', 'canaaniti', 'tweet', 'voodoo', 'book', 'isee', 'speech', 'woolfe',\n",
    "                        'coffee', 'ffoo', 'refugees', 'google', 'shooting', 'hooligans', 'desiree', 'retweeted', 'microaree',\n",
    "                        'keep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "\n",
    "def clean_vowels(text):\n",
    "    new_text = text\n",
    "    words = text.split()\n",
    "    \n",
    "    for word in words:\n",
    "        if word.lower() not in italian_dict and word.lower() not in correct_words_vowels:\n",
    "        #if word.lower() not in correct_words_vowels:\n",
    "            new_string = word[0]\n",
    "            for i in range(1, len(word)):\n",
    "                if word[i].lower() not in vowels:\n",
    "                    new_string = new_string + word[i]\n",
    "                else:\n",
    "                    if(word[i].lower() != word[i-1].lower()):\n",
    "                        new_string = new_string + word[i] \n",
    "\n",
    "            new_text = new_text.replace(word, new_string)\n",
    "        \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_vowels)\n",
    "df1['text'] = df1['text'].apply(clean_vowels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Removing nearby equal consonants if they are more than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "consonants = ['b','c','d','f','g','h','k','l','m','n','p','q','r','s','t','v','x','y','z']\n",
    "\n",
    "def clean_consonants(text):\n",
    "    new_text = text\n",
    "    words = text.split()\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) > 2: #nn non viene cambiato\n",
    "            new_string = word[0]\n",
    "            for i in range(1, len(word)):\n",
    "                if word[i].lower() not in consonants:\n",
    "                    new_string = new_string + word[i]\n",
    "                else:\n",
    "                    if(word[i].lower() != word[i-1].lower()):\n",
    "                        new_string = new_string + word[i]\n",
    "                    elif i>=2 and (word[i].lower() != word[i-2].lower()):\n",
    "                        new_string = new_string + word[i]\n",
    "\n",
    "            new_text = new_text.replace(word, new_string)\n",
    "        \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_consonants)\n",
    "df1['text'] = df1['text'].apply(clean_consonants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Sticking the apostrophe (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stick_apostrophe_text(text):\n",
    "    text = re.sub(r\" ’\", \"’\", text)\n",
    "    return re.sub(r\" '\", \"'\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(stick_apostrophe_text)\n",
    "df1['text'] = df1['text'].apply(stick_apostrophe_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature extraction: lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(text):\n",
    "    lemmas = []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc:\n",
    "        lemmas.append(token.lemma_)\n",
    "        \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemma'] = df['text'].apply(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature extraction: PoS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Words can be grouped into classes called Part of Speech (PoS) or morphological classes. \n",
    "<p> Traditional grammar provides for a few types of PoS (noun, verb, adjective, preposition, adverb, conjunction, etc.). \n",
    "<p> La PoS di una parola fornisce informazione fondamentale per determinare il ruolo della parola stessa e di quelle vicine nella frase.\n",
    "<p> To see what PoS tag means, we can use spacy.explain()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(text):\n",
    "    pos_list = []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc:\n",
    "        pos_list.append(token.pos_)\n",
    "        \n",
    "    return pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pos'] = df1['text'].apply(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature extraction: Dep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what PoS tag means, we can use spacy.explain()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep(text):\n",
    "    dep_list = []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc:\n",
    "        dep_list.append(token.dep_)\n",
    "        \n",
    "    return dep_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dep'] = df1['text'].apply(dep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature extraction: Word Polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Italian Lexicon of Sentiments was developed semi-automatically by ItalWordNet v.2 from a list of 1,000 manually checked keywords. It contains 24,293 lexical entries annotated with positive/negative/neutral polarity. It is distributed in LMF format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li> Tag 'LexicalEntry' with attribute 'id' from 'id_0' to 'id_25097'\n",
    "    <li> Tag 'Lemma' with attribute 'writtenForm' containing the lemma of the word (example: 'di_cassetta')\n",
    "    <li> Tag 'Sentiment' with attribute 'polarity' ('negative'/'neutral'/'positive')\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data inside the xml \n",
    "# file to a variable under the name  \n",
    "# data \n",
    "with open('it-sentiment_lexicon.lmf.xml', 'r') as f: \n",
    "    data = f.read() \n",
    "\n",
    "# Passing the stored data inside \n",
    "# the beautifulsoup parser, storing \n",
    "# the returned object  \n",
    "Bs_data = BeautifulSoup(data, \"xml\") \n",
    "\n",
    "word_polarity = {}\n",
    "\n",
    "lemma_unique = Bs_data.find_all('Lemma')         #Finding all instances of tag 'Lemma'\n",
    "sentiment_unique = Bs_data.find_all('Sentiment') \n",
    "\n",
    "if len(lemma_unique) != len(sentiment_unique):\n",
    "    print('ERRORE')\n",
    "\n",
    "for i in range(0, len(lemma_unique)):\n",
    "    word = lemma_unique[i].get('writtenForm') #Extracting the data stored in a specific attributes of the 'Lemma' tag\n",
    "    word = re.sub(r'_', ' ', word)\n",
    "    \n",
    "    polarity = sentiment_unique[i].get('polarity')\n",
    "    \n",
    "    word_polarity[word] = polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_polarity(lemmas):\n",
    "    \n",
    "    polarity = []\n",
    "    \n",
    "    for word in lemmas:\n",
    "        if word in word_polarity:\n",
    "            polarity.append(word_polarity[word])\n",
    "        else:\n",
    "            polarity.append('neutral')\n",
    "            \n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_polarity'] = df['lemma'].apply(get_word_polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    tknzr=SocialTokenizer(lowercase=False)\n",
    "    return tknzr.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['text'].apply(tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Sticking the apostrophe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_char = ['l', 'un', 'dell', 'all', 'dall', 'nell', 'sull', 'c', 'n']\n",
    "apostrophes = [\"'\", \"’\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stick_apostrophe(tokens):\n",
    "    to_pop = []\n",
    "    for i in range(0, len(tokens)-1):\n",
    "        if tokens[i] in pre_char and tokens[i+1] in apostrophes:\n",
    "            tokens[i] = tokens[i] + \"'\"\n",
    "            to_pop.append(i+1)\n",
    "    \n",
    "    result_tokens = []\n",
    "    for i in range(0, len(tokens)):\n",
    "        if i not in to_pop:\n",
    "            result_tokens.append(tokens[i])  \n",
    "        \n",
    "    return result_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(stick_apostrophe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Replacement of the abbreviations with the respective words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_word = {'cmq':'comunque', 'gov':'governatori', 'fb':'facebook', 'tw':'twitter', 'juve':'juventus', 'ing':'ingegnere', \n",
    "             'sx':'sinistra', 'qdo':'quando', 'rep':'repubblica', 'grz':'grazie', 'ita':'italia', 'mln':'milioni', \n",
    "             'mld':'miliardi', 'pke':'perche', 'anke':'anche', 'cm':'come', 'dlla':'della', 'dlle':'delle', 'qst':'questa',\n",
    "             'ke':'che', 'nn':'non', 'sn':'sono', 'cn':'con', 'xk':'perche', 'xke':'perche', 'art':'articolo',\n",
    "             'tv':'televisore', '€':'euro', 'xché':'perché', 'xké':'perché', 'pkè':'perché'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_abbreviation(tokens):\n",
    "    result = [] \n",
    "    \n",
    "    for word in tokens:\n",
    "        if word.lower() in abbr_word:\n",
    "            result.append(abbr_word[word.lower()])\n",
    "        else:\n",
    "            result.append(word)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(replace_abbreviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Replacing Acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "acronyms = {'unhcr':['alto', 'commissariato', 'nazioni', 'unite', 'rifugiati'], \n",
    "            'onu':['organizzazione', 'delle', 'nazioni', 'unite'],\n",
    "            'fdi':['fratelli', 'italia'], \n",
    "            'msna':['minori', 'stranieri', 'accompagnati'], \n",
    "            'rdc':['reddito', 'di', 'cittadinanza'],\n",
    "            'gus':['gruppo', 'umana', 'solidarieta'], \n",
    "            'sprar':['sistema', 'protezione', 'richiedenti', 'asilo'],\n",
    "            'anpi':['associazione', 'nazionale', 'partigiani', 'italia'], \n",
    "            'anac':['autorita', 'nazionale', 'anticorruzione'],\n",
    "            'lgbt':['lesbiche', 'gay', 'bisessuali', 'transgender'], \n",
    "            'ln':['lega', 'nord'], \n",
    "            'ue':['unione', 'europea'],\n",
    "            'msf':['medici','senza','frontiere'], \n",
    "            'ispi':['istituto','studi','politica','internazionale'],\n",
    "            'cpr':['centri','permanenza','rimpatri'], \n",
    "            'pd':['partito', 'democratico'], \n",
    "            'gc':['guardia', 'costiera'],\n",
    "            'inps':['istituto','nazionale','previdenza','sociale'],\n",
    "            'cdm':['consiglio', 'dei', 'ministri'], \n",
    "            'pdl':['popolo', 'della', 'liberta'], \n",
    "            'atac':['azienda', 'tramvie', 'autobus', 'comune', 'roma'],\n",
    "            'tav':['treno', 'alta', 'velocita'], \n",
    "            'isee':['situazione', 'economica', 'equivalente'],\n",
    "            'usa':['stati', 'uniti', 'd', 'america'], \n",
    "            'onlus':['organizzazione', 'lucrativa', 'utilita', 'sociale'],\n",
    "            'acsim':['associazione', 'centro', 'servizi', 'immigrati', 'marche'], \n",
    "            'aids':['sindrome', 'immuno', 'deficienza', 'acquisita'], \n",
    "            'eu':['unione', 'europea'],\n",
    "            'ong':['organizzazione', 'governativa'], \n",
    "            'nwo':['nuovo', 'ordine', 'mondiale'],\n",
    "            'pil':['prodotto', 'interno', 'lordo'], \n",
    "            'cgil':['confederazione', 'generale', 'lavoro'],\n",
    "            'cdt':['corriere', 'ticino'], \n",
    "            'ptv':['societa', 'televisiva', 'pakistan'],\n",
    "            'syriza':['coalizione', 'sinistra', 'radicale'], \n",
    "            'fiom':['federazione', 'impiegati', 'operai', 'metallurgici'],\n",
    "            'lgbtq':['lesbiche', 'gay', 'bisessuali', 'transgender', 'queer'], \n",
    "            'rpl':['radio', 'padania', 'libera'],\n",
    "            'arci':['associazione', 'ricreativa', 'culturale', 'italiana'],\n",
    "            'ofcs':['osservatorio', 'focus', 'cultura', 'sicurezza'],\n",
    "            'm5s':['movimento', 'cinque', 'stelle'],\n",
    "            'wm5s':['movimento', 'cinque', 'stelle'],\n",
    "            'mef':['ministero', 'dell', 'economia', 'e', 'delle', 'finanze'],\n",
    "            'cnel':['consiglio', 'nazionale', 'dell', 'economia', 'e', 'del', 'lavoro'],\n",
    "            'fdian':['fratelli', 'di', 'italia', 'alleanza', 'nazionale'],\n",
    "            'ecm':['educazione', 'continua', 'in', 'medicina'],\n",
    "            'cie':['carta', 'di', 'identità', 'elettronica'],\n",
    "            'tg':['telegiornale'],\n",
    "            'rai':['radiotelevisione', 'italiana'],\n",
    "            'anpal':['agenzia', 'nazionale', 'politiche', 'attive', 'lavoro'],\n",
    "            'def':['documento', 'di', 'economia', 'e', 'finanza'],\n",
    "            'cr':['consiglio', 'regionale'],\n",
    "            'ama':['azienda', 'municipale', 'ambiente'],\n",
    "            'cesedi':['centro', 'servizi', 'didattici'],\n",
    "            'ffoo':['forze', 'dell', 'ordine'],\n",
    "            'reyn':['rete', 'per', 'la', 'prima', 'infanzia', 'rom'],\n",
    "            'rmc':['radio', 'monte', 'carlo'],\n",
    "            'ddl':['disegno', 'di', 'legge']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_acronyms(tokens):\n",
    "    for i in range(0, len(tokens)):\n",
    "        word = tokens[i]\n",
    "        if word.lower() in acronyms:\n",
    "            tokens[i] = acronyms[word.lower()][0]\n",
    "            if len(acronyms[word.lower()]) > 1:\n",
    "                for j in range(1, len(acronyms[word.lower()])):\n",
    "                    tokens.insert(i+j, acronyms[word.lower()][j])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(replace_acronyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Replacing other emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = {'✔':['segno', 'di', 'spunta'],\n",
    "           '♻':['simbolo', 'del', 'riciclaggio'],\n",
    "           '▶':['pulsante', 'di', 'riproduzione'],\n",
    "           '🖊':['penna', 'a', 'sfera'],\n",
    "           '❤':['cuore', 'rosso']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_others_emojis(tokens):\n",
    "    for i in range(0, len(tokens)):\n",
    "        word = tokens[i]\n",
    "        if word in symbols:\n",
    "            tokens[i] = symbols[word][0]\n",
    "            if len(symbols[word]) > 1:\n",
    "                for j in range(1, len(symbols[word])):\n",
    "                    tokens.insert(i+j, symbols[word][j])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(replace_others_emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature extraction: percentage of Bad Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_bad_words(tokens):\n",
    "    n_words = 0\n",
    "    n_bad_words = 0\n",
    "    \n",
    "    for word in tokens:\n",
    "        if word != '<' and word != '>':\n",
    "            n_words = n_words + 1\n",
    "    \n",
    "    for word in tokens:\n",
    "        if word.lower() in bad_words_dict:\n",
    "            n_bad_words = n_bad_words + 1\n",
    "        \n",
    "    return ((n_bad_words*100)//n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['%bad_words'] = df['tokens'].apply(percentage_bad_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('italian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokens):\n",
    "    result = []\n",
    "        \n",
    "    for word in tokens:\n",
    "        if word != '<' and word != '>':\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            result.append(stemmed_word)\n",
    "        else:\n",
    "            result.append(word)\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stem'] = df['tokens'].apply(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Saving the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 6837, differences: 4604\n"
     ]
    }
   ],
   "source": [
    "#Vedo la differenza tra le varie liste\n",
    "count = 0\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    row = df.iloc[i]\n",
    "    len_token = len(row['tokens'])\n",
    "    len_lemma = len(row['lemma'])\n",
    "    len_pos = len(row['pos'])\n",
    "    len_polarity = len(row['word_polarity'])\n",
    "    \n",
    "    if (len_token != len_lemma) and (len_token != len_pos) and (len_token != len_polarity):\n",
    "        count = count + 1\n",
    "        \n",
    "print('Rows: {}, differences: {}'.format(len(df), count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hs</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>text_length</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>%CAPS-LOCK words</th>\n",
       "      <th>esclamations</th>\n",
       "      <th>questions</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>word_polarity</th>\n",
       "      <th>tokens</th>\n",
       "      <th>%bad_words</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2066</td>\n",
       "      <td>È terrorismo anche questo , per mettere in uno stato di soggezione le persone e renderle innocue , mentre qualcuno . . .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[essere, terrorismo, anche, questo, ,, per, mettere, in, uno, stato, di, soggezione, il, persona, e, rendere, lo, innocuo, ,, mentre, qualcuno, ., ., .]</td>\n",
       "      <td>[AUX, NOUN, ADV, PRON, PUNCT, ADP, VERB, ADP, DET, NOUN, ADP, NOUN, DET, NOUN, CCONJ, VERB, DET, NOUN, PUNCT, SCONJ, PRON, PUNCT, PUNCT, PUNCT]</td>\n",
       "      <td>[cop, ROOT, advmod, nsubj, punct, mark, advcl, case, det, obl, case, nmod, det, obj, cc, conj, det, obj, punct, mark, advcl, punct, punct, punct]</td>\n",
       "      <td>[neutral, negative, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[È, terrorismo, anche, questo, ,, per, mettere, in, uno, stato, di, soggezione, le, persone, e, renderle, innocue, ,, mentre, qualcuno, ., ., .]</td>\n",
       "      <td>0</td>\n",
       "      <td>[è, terror, anche, quest, ,, per, mett, in, uno, stat, di, soggezion, le, person, e, rend, innocu, ,, mentr, qualcun, ., ., .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2045</td>\n",
       "      <td>infatti finché ci hanno guadagnato con i campi &lt; rom &gt; tutto era ok con &lt; Alemanno &gt; &lt; Ipocriti &gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[infatti, finché, ci, avere, guadagnare, con, il, campo, &lt;, rom, &gt;, tutto, essere, ok, con, &lt;, Alemanno, &gt;, &lt;, ipocriti, &gt;]</td>\n",
       "      <td>[ADV, SCONJ, PRON, AUX, VERB, ADP, DET, NOUN, SYM, NOUN, SYM, PRON, AUX, NOUN, ADP, SYM, PROPN, SYM, SYM, PROPN, SYM]</td>\n",
       "      <td>[advmod, mark, obj, aux, advcl, case, det, obl, nmod, nmod, nmod, nsubj, cop, nmod, case, nmod, flat:name, nsubj, flat:name, flat:name, ROOT]</td>\n",
       "      <td>[neutral, neutral, neutral, negative, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[infatti, finché, ci, hanno, guadagnato, con, i, campi, &lt;, rom, &gt;, tutto, era, ok, con, &lt;, Alemanno, &gt;, &lt;, Ipocriti, &gt;]</td>\n",
       "      <td>0</td>\n",
       "      <td>[infatt, finc, ci, hann, guadagn, con, i, camp, &lt;, rom, &gt;, tutt, era, ok, con, &lt;, alemann, &gt;, &lt;, ipocr, &gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>Corriere : Tangenti , Mafia Capitale dimenticata Mazzette su buche e campi rom &lt; roma &gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Corriere, :, Tangenti, ,, mafia, Capitale, dimenticare, mazzette, su, buca, e, campo, rom, &lt;, roma, &gt;]</td>\n",
       "      <td>[NOUN, PUNCT, PROPN, PUNCT, PROPN, PROPN, VERB, PROPN, ADP, NOUN, CCONJ, NOUN, NOUN, SYM, NOUN, SYM]</td>\n",
       "      <td>[nmod, punct, conj, punct, flat:name, flat:name, acl, flat:name, case, nmod, cc, conj, nmod, nmod, compound, ROOT]</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, negative, neutral, neutral, neutral, neutral, negative, neutral, positive, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[Corriere, :, Tangenti, ,, Mafia, Capitale, dimenticata, Mazzette, su, buche, e, campi, rom, &lt;, roma, &gt;]</td>\n",
       "      <td>0</td>\n",
       "      <td>[corr, :, tangent, ,, maf, capital, dimentic, mazzett, su, buch, e, camp, rom, &lt;, rom, &gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1259</td>\n",
       "      <td>ad uno ad uno , perché quando i migranti israeliti arrivarono in terra di Canaan fecero fuori tutti i Canaaniti .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[a, uno, di, uno, ,, perché, quando, il, migrante, israelire, arrivare, in, terra, di, Canaan, fare, fuori, tutto, il, Canaaniti, .]</td>\n",
       "      <td>[ADP, PRON, ADP, PRON, PUNCT, SCONJ, SCONJ, DET, NOUN, ADJ, VERB, ADP, NOUN, ADP, PROPN, VERB, ADV, DET, DET, PROPN, PUNCT]</td>\n",
       "      <td>[case, ROOT, case, nmod, punct, mark, mark, det, nsubj, amod, advcl, case, obl, case, nmod, advcl, advmod, det:predet, det, nsubj, punct]</td>\n",
       "      <td>[neutral, positive, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[ad, uno, ad, uno, ,, perché, quando, i, migranti, israeliti, arrivarono, in, terra, di, Canaan, fecero, fuori, tutti, i, Canaaniti, .]</td>\n",
       "      <td>0</td>\n",
       "      <td>[ad, uno, ad, uno, ,, perc, quand, i, migrant, israel, arriv, in, terr, di, canaan, fecer, fuor, tutt, i, canaan, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>949</td>\n",
       "      <td>Il divertimento del giorno ? Trovare i patrioti italiani che inneggiano contro i rom facendo la spesa alla &lt; Lidl &gt; ( multinazionale tedesca ) .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[il, divertimento, di, il, giorno, ?, trovare, il, patriote, italiano, che, inneggiare, contro, il, rom, fare, il, spesa, a, il, &lt;, Lidl, &gt;, (, multinazionale, tedesco, ), .]</td>\n",
       "      <td>[DET, NOUN, ADP, DET, NOUN, PUNCT, VERB, DET, NOUN, ADJ, PRON, VERB, ADP, DET, NOUN, VERB, DET, NOUN, ADP, DET, SYM, PROPN, SYM, PUNCT, ADJ, ADJ, PUNCT, PUNCT]</td>\n",
       "      <td>[det, ROOT, case, det, nmod, punct, ROOT, det, obj, amod, nsubj, acl:relcl, case, det, obl, advcl, det, obj, case, det, obl, flat:name, flat:name, punct, amod, amod, punct, punct]</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[Il, divertimento, del, giorno, ?, Trovare, i, patrioti, italiani, che, inneggiano, contro, i, rom, facendo, la, spesa, alla, &lt;, Lidl, &gt;, (, multinazionale, tedesca, ), .]</td>\n",
       "      <td>0</td>\n",
       "      <td>[il, divert, del, giorn, ?, trov, i, patriot, italian, che, innegg, contr, i, rom, fac, la, spes, alla, &lt;, lidl, &gt;, (, multinazional, tedesc, ), .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6832</th>\n",
       "      <td>9340</td>\n",
       "      <td>Gli stati nazionali devono essere pronti a rinunciare alla propria sovranità . Lo ha detto la Merkel , che ha aggiunto che gli stati nazionali non devono ascoltare la volontà dei loro cittadini quando si tratta di questioni che riguardano immigrazione , confini , o persino sovranità</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[il, stato, nazionale, dovere, essere, pronto, a, rinunciare, a, il, proprio, sovranità, ., lo, avere, dire, il, Merkel, ,, che, avere, aggiungere, che, il, stato, nazionale, non, dovere, ascoltare, il, volontà, di, il, loro, cittadino, quando, si, trattare, di, questione, che, riguardare, immigrazione, ,, confine, ,, o, persino, sovranità]</td>\n",
       "      <td>[DET, NOUN, ADJ, AUX, AUX, ADJ, ADP, VERB, ADP, DET, DET, NOUN, PUNCT, PRON, AUX, VERB, DET, PROPN, PUNCT, PRON, AUX, VERB, SCONJ, DET, NOUN, ADJ, ADV, AUX, VERB, DET, NOUN, ADP, DET, DET, NOUN, SCONJ, PRON, VERB, ADP, NOUN, PRON, VERB, NOUN, PUNCT, NOUN, PUNCT, CCONJ, ADV, NOUN]</td>\n",
       "      <td>[det, nsubj, amod, aux, cop, ROOT, mark, advcl, case, det, det:poss, obl, punct, obj, aux, ROOT, det, nsubj, punct, nsubj, aux, acl:relcl, mark, det, nsubj, amod, advmod, aux, ccomp, det, obj, case, det, det:poss, nmod, mark, expl, advcl, case, obl, nsubj, acl:relcl, obj, punct, conj, punct, cc, advmod, conj]</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, negative, negative, neutral, neutral, neutral, neutral, negative, neutral, neutral, neutral, neutral, neutral, None, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, negative, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[Gli, stati, nazionali, devono, essere, pronti, a, rinunciare, alla, propria, sovranità, ., Lo, ha, detto, la, Merkel, ,, che, ha, aggiunto, che, gli, stati, nazionali, non, devono, ascoltare, la, volontà, dei, loro, cittadini, quando, si, tratta, di, questioni, che, riguardano, immigrazione, ,, confini, ,, o, persino, sovranità]</td>\n",
       "      <td>0</td>\n",
       "      <td>[gli, stat, nazional, dev, esser, pront, a, rinunc, alla, propr, sovran, ., lo, ha, dett, la, merkel, ,, che, ha, aggiunt, che, gli, stat, nazional, non, dev, ascolt, la, volont, dei, lor, cittadin, quand, si, tratt, di, question, che, riguard, immigr, ,, confin, ,, o, persin, sovran]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6833</th>\n",
       "      <td>9121</td>\n",
       "      <td>Il ministro dell' interno della Germania &lt; Horst Sehofer &gt; , sta facendo la proposta di dare soldi agli immigrati che vogliono tornare a casa e aiutarli a creare un' attività a casa loro e fare business con la Germania . Chi paga ? Una parte i crucchi e il resto l' Europa , cioè io e voi !</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[il, ministro, di, il, interno, di, il, Germania, &lt;, Horst, Sehofer, &gt;, ,, stare, fare, il, proposta, di, dare, soldo, a, il, immigrato, che, volere, tornare, a, casa, e, aiutare, li, a, creare, uno, attività, a, casa, loro, e, fare, business, con, il, Germania, ., chi, pagare, ?, uno, parte, il, crucco, e, il, resto, il, Europa, ,, cioè, io, e, voi, !]</td>\n",
       "      <td>[DET, NOUN, ADP, DET, NOUN, ADP, DET, PROPN, SYM, PROPN, PROPN, SYM, PUNCT, AUX, VERB, DET, NOUN, ADP, VERB, NOUN, ADP, DET, NOUN, PRON, AUX, VERB, ADP, NOUN, CCONJ, VERB, PRON, ADP, VERB, DET, NOUN, ADP, NOUN, PRON, CCONJ, VERB, NOUN, ADP, DET, PROPN, PUNCT, PRON, VERB, PUNCT, DET, NOUN, DET, NOUN, CCONJ, DET, NOUN, DET, PROPN, PUNCT, CCONJ, PRON, CCONJ, PRON, PUNCT]</td>\n",
       "      <td>[det, nsubj, case, det, nmod, case, det, nmod, nmod, flat:name, flat:name, flat:name, punct, aux, ROOT, det, obj, mark, acl, obj, case, det, obl, nsubj, aux, acl:relcl, case, obl, cc, conj, obj, mark, xcomp, det, obj, case, obl, nmod, cc, conj, obj, case, det, nmod, punct, nsubj, ROOT, punct, det, ROOT, det, nmod, cc, det, conj, det, nmod, punct, cc, conj, cc, conj, punct]</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, negative, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, positive, neutral, neutral, neutral, positive, neutral, neutral, positive, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral]</td>\n",
       "      <td>[Il, ministro, dell', interno, della, Germania, &lt;, Horst, Sehofer, &gt;, ,, sta, facendo, la, proposta, di, dare, soldi, agli, immigrati, che, vogliono, tornare, a, casa, e, aiutarli, a, creare, un', attività, a, casa, loro, e, fare, business, con, la, Germania, ., Chi, paga, ?, Una, parte, i, crucchi, e, il, resto, l', Europa, ,, cioè, io, e, voi, !]</td>\n",
       "      <td>0</td>\n",
       "      <td>[il, ministr, dell', intern, dell, german, &lt;, horst, sehofer, &gt;, ,, sta, fac, la, propost, di, dar, sold, agli, immigr, che, vogl, torn, a, cas, e, aiut, a, cre, un', attiv, a, cas, lor, e, far, business, con, la, german, ., chi, pag, ?, una, part, i, crucc, e, il, rest, l', europ, ,, cio, io, e, voi, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>8549</td>\n",
       "      <td>&lt; Salvini &gt; : In Italia troppi si sono montati la testa , io ringrazio Dio e voi per questi mesi straordinari . Vi raccontavano che su immigrazione non si poteva fare nulla , è bastato usare buonsenso e coraggio . &lt; io ci sono &gt; &lt; piazza del popolo &gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;, Salvini, &gt;, :, in, Italia, troppo, si, essere, montare, il, testa, ,, io, ringrazio, Dio, e, voi, per, questo, mese, straordinario, ., vi, raccontare, che, su, immigrazione, non, si, potere, fare, nulla, ,, essere, bastare, usare, buonsenso, e, coraggio, ., &lt;, io, ci, essere, &gt;, &lt;, piazza, di, il, popolo, &gt;]</td>\n",
       "      <td>[SYM, PROPN, SYM, PUNCT, ADP, PROPN, DET, PRON, AUX, VERB, DET, NOUN, PUNCT, PRON, VERB, NOUN, CCONJ, PRON, ADP, DET, NOUN, ADJ, PUNCT, PRON, VERB, SCONJ, ADP, NOUN, ADV, PRON, AUX, VERB, PRON, PUNCT, AUX, VERB, VERB, NOUN, CCONJ, NOUN, PUNCT, SYM, PRON, PRON, VERB, SYM, SYM, NOUN, ADP, DET, NOUN, SYM]</td>\n",
       "      <td>[ROOT, flat:name, flat:name, punct, case, obl, nsubj, expl, aux, ROOT, det, obj, punct, nsubj, advcl, obj, cc, conj, case, det, obl, amod, punct, iobj, ROOT, mark, case, obl, advmod, expl:impers, aux, ccomp, obj, punct, aux, conj, xcomp, obj, cc, conj, punct, obl, nsubj, expl, ROOT, nsubj, flat:name, compound, case, det, nmod, flat:name]</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral, neutral, negative, neutral, neutral, neutral, neutral, positive, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, negative, neutral, neutral, neutral, None, neutral, neutral, neutral, negative, neutral, neutral, positive, neutral, positive, neutral, positive, neutral, neutral, positive, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[&lt;, Salvini, &gt;, :, In, Italia, troppi, si, sono, montati, la, testa, ,, io, ringrazio, Dio, e, voi, per, questi, mesi, straordinari, ., Vi, raccontavano, che, su, immigrazione, non, si, poteva, fare, nulla, ,, è, bastato, usare, buonsenso, e, coraggio, ., &lt;, io, ci, sono, &gt;, &lt;, piazza, del, popolo, &gt;]</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;, salvin, &gt;, :, in, ital, tropp, si, son, mont, la, test, ,, io, ringraz, dio, e, voi, per, quest, mes, straordinar, ., vi, raccont, che, su, immigr, non, si, pot, far, null, ,, è, bast, usar, buonsens, e, coragg, ., &lt;, io, ci, son, &gt;, &lt;, piazz, del, popol, &gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>9240</td>\n",
       "      <td>Chi giubila in buona fede non ha capito niente . Purtroppo credo che i più non siano in buona fede . I migranti sono un grosso business e chi finora li ha voluti non vuole perdere questo guadagno</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[chi, giubilare, in, buono, fede, non, avere, capire, niente, ., purtroppo, credere, che, il, più, non, essere, in, buono, fede, ., il, migrante, essere, uno, grosso, business, e, chi, finora, li, avere, volere, non, volere, perdere, questo, guadagno]</td>\n",
       "      <td>[PRON, VERB, ADP, ADJ, NOUN, ADV, AUX, VERB, PRON, PUNCT, ADV, VERB, SCONJ, DET, ADV, ADV, AUX, ADP, ADJ, NOUN, PUNCT, DET, NOUN, AUX, DET, ADJ, NOUN, CCONJ, PRON, ADV, PRON, AUX, VERB, ADV, AUX, VERB, DET, NOUN]</td>\n",
       "      <td>[nsubj, advcl, case, amod, obl, advmod, aux, ROOT, obj, punct, advmod, ROOT, mark, det, advmod, advmod, cop, case, amod, ccomp, punct, det, nsubj, cop, det, amod, ROOT, cc, nsubj, advmod, obj, aux, acl:relcl, advmod, aux, conj, det, obj]</td>\n",
       "      <td>[neutral, positive, neutral, positive, positive, None, negative, positive, negative, neutral, neutral, positive, neutral, neutral, neutral, None, neutral, neutral, positive, positive, neutral, neutral, neutral, neutral, positive, neutral, positive, neutral, neutral, neutral, neutral, negative, neutral, None, neutral, negative, neutral, positive]</td>\n",
       "      <td>[Chi, giubila, in, buona, fede, non, ha, capito, niente, ., Purtroppo, credo, che, i, più, non, siano, in, buona, fede, ., I, migranti, sono, un, grosso, business, e, chi, finora, li, ha, voluti, non, vuole, perdere, questo, guadagno]</td>\n",
       "      <td>0</td>\n",
       "      <td>[chi, giubil, in, buon, fed, non, ha, cap, nient, ., purtropp, cred, che, i, più, non, sian, in, buon, fed, ., i, migrant, son, un, gross, business, e, chi, finor, li, ha, vol, non, vuol, perd, quest, guadagn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>8000</td>\n",
       "      <td>I giovani cristiani in &lt; Etiopia &gt; sono indotti dagli islamisti a convertirsi all' Islam con promesse di lavoro , istruzione e aiuti abitativi . Alcune miniere impiegano solo musulmani . Lo riferisce ad Acs un leader cristiano locale , anonimo per motivi di sicurezza . Preghiamo per loro !</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[il, giovane, cristiano, in, &lt;, Etiopia, &gt;, essere, indurre, da, il, islamista, a, convertire, si, a, il, Islam, con, promessa, di, lavoro, ,, istruzione, e, aiuto, abitativo, ., alcuno, miniera, impiegare, solo, musulmano, ., lo, riferire, a, Acs, uno, leader, cristiano, locale, ,, anonimo, per, motivo, di, sicurezza, ., Preghare, per, loro, !]</td>\n",
       "      <td>[DET, NOUN, ADJ, ADP, SYM, PROPN, SYM, AUX, VERB, ADP, DET, NOUN, ADP, VERB, PRON, ADP, DET, PROPN, ADP, NOUN, ADP, NOUN, PUNCT, NOUN, CCONJ, NOUN, ADJ, PUNCT, DET, NOUN, VERB, ADV, NOUN, PUNCT, PRON, VERB, ADP, PROPN, DET, NOUN, ADJ, ADJ, PUNCT, ADJ, ADP, NOUN, ADP, NOUN, PUNCT, VERB, ADP, PRON, PUNCT]</td>\n",
       "      <td>[det, nsubj:pass, amod, case, nmod, flat:name, flat:name, aux:pass, ROOT, case, det, obl, mark, xcomp, expl, case, det, obl, case, obl, case, nmod, punct, conj, cc, conj, amod, punct, det, nsubj, ROOT, advmod, obj, punct, obj, ROOT, case, obl, det, nsubj, amod, amod, punct, amod, case, obl, case, nmod, punct, ROOT, case, obl, punct]</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, negative, neutral, positive, neutral, neutral, neutral, positive, neutral, neutral, positive, positive, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[I, giovani, cristiani, in, &lt;, Etiopia, &gt;, sono, indotti, dagli, islamisti, a, convertirsi, all', Islam, con, promesse, di, lavoro, ,, istruzione, e, aiuti, abitativi, ., Alcune, miniere, impiegano, solo, musulmani, ., Lo, riferisce, ad, Acs, un, leader, cristiano, locale, ,, anonimo, per, motivi, di, sicurezza, ., Preghiamo, per, loro, !]</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, giovan, cristian, in, &lt;, etiop, &gt;, son, indott, dagl, islam, a, convert, all', islam, con, promess, di, lavor, ,, istruzion, e, aiut, abit, ., alcun, min, impieg, sol, musulman, ., lo, rifer, ad, acs, un, leader, crist, local, ,, anonim, per, mot, di, sicurezz, ., preg, per, lor, !]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6837 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0     2066   \n",
       "1     2045   \n",
       "2       61   \n",
       "3     1259   \n",
       "4      949   \n",
       "...    ...   \n",
       "6832  9340   \n",
       "6833  9121   \n",
       "6834  8549   \n",
       "6835  9240   \n",
       "6836  8000   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                    text  \\\n",
       "0                                                                                                                                                                               È terrorismo anche questo , per mettere in uno stato di soggezione le persone e renderle innocue , mentre qualcuno . . .   \n",
       "1                                                                                                                                                                                                      infatti finché ci hanno guadagnato con i campi < rom > tutto era ok con < Alemanno > < Ipocriti >   \n",
       "2                                                                                                                                                                                                                Corriere : Tangenti , Mafia Capitale dimenticata Mazzette su buche e campi rom < roma >   \n",
       "3                                                                                                                                                                                      ad uno ad uno , perché quando i migranti israeliti arrivarono in terra di Canaan fecero fuori tutti i Canaaniti .   \n",
       "4                                                                                                                                                       Il divertimento del giorno ? Trovare i patrioti italiani che inneggiano contro i rom facendo la spesa alla < Lidl > ( multinazionale tedesca ) .   \n",
       "...                                                                                                                                                                                                                                                                                                  ...   \n",
       "6832         Gli stati nazionali devono essere pronti a rinunciare alla propria sovranità . Lo ha detto la Merkel , che ha aggiunto che gli stati nazionali non devono ascoltare la volontà dei loro cittadini quando si tratta di questioni che riguardano immigrazione , confini , o persino sovranità   \n",
       "6833  Il ministro dell' interno della Germania < Horst Sehofer > , sta facendo la proposta di dare soldi agli immigrati che vogliono tornare a casa e aiutarli a creare un' attività a casa loro e fare business con la Germania . Chi paga ? Una parte i crucchi e il resto l' Europa , cioè io e voi !   \n",
       "6834                                          < Salvini > : In Italia troppi si sono montati la testa , io ringrazio Dio e voi per questi mesi straordinari . Vi raccontavano che su immigrazione non si poteva fare nulla , è bastato usare buonsenso e coraggio . < io ci sono > < piazza del popolo >   \n",
       "6835                                                                                                 Chi giubila in buona fede non ha capito niente . Purtroppo credo che i più non siano in buona fede . I migranti sono un grosso business e chi finora li ha voluti non vuole perdere questo guadagno   \n",
       "6836  I giovani cristiani in < Etiopia > sono indotti dagli islamisti a convertirsi all' Islam con promesse di lavoro , istruzione e aiuti abitativi . Alcune miniere impiegano solo musulmani . Lo riferisce ad Acs un leader cristiano locale , anonimo per motivi di sicurezza . Preghiamo per loro !   \n",
       "\n",
       "      hs  stereotype  text_length  hashtags  %CAPS-LOCK words  esclamations  \\\n",
       "0      0           0          118         0                 4             0   \n",
       "1      0           0           93         3                 0             0   \n",
       "2      0           0           84         1                 0             0   \n",
       "3      0           0          114         0                 0             0   \n",
       "4      0           0          138         1                 0             0   \n",
       "...   ..         ...          ...       ...               ...           ...   \n",
       "6832   0           0          283         0                 0             0   \n",
       "6833   0           0          277         1                 0             1   \n",
       "6834   0           0          233         3                 0             0   \n",
       "6835   0           0          198         0                 2             0   \n",
       "6836   0           1          283         1                 3             1   \n",
       "\n",
       "      questions  \\\n",
       "0             0   \n",
       "1             0   \n",
       "2             0   \n",
       "3             0   \n",
       "4             1   \n",
       "...         ...   \n",
       "6832          0   \n",
       "6833          1   \n",
       "6834          0   \n",
       "6835          0   \n",
       "6836          0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                    lemma  \\\n",
       "0                                                                                                                                                                                                                [essere, terrorismo, anche, questo, ,, per, mettere, in, uno, stato, di, soggezione, il, persona, e, rendere, lo, innocuo, ,, mentre, qualcuno, ., ., .]   \n",
       "1                                                                                                                                                                                                                                             [infatti, finché, ci, avere, guadagnare, con, il, campo, <, rom, >, tutto, essere, ok, con, <, Alemanno, >, <, ipocriti, >]   \n",
       "2                                                                                                                                                                                                                                                                 [Corriere, :, Tangenti, ,, mafia, Capitale, dimenticare, mazzette, su, buca, e, campo, rom, <, roma, >]   \n",
       "3                                                                                                                                                                                                                                    [a, uno, di, uno, ,, perché, quando, il, migrante, israelire, arrivare, in, terra, di, Canaan, fare, fuori, tutto, il, Canaaniti, .]   \n",
       "4                                                                                                                                                                                          [il, divertimento, di, il, giorno, ?, trovare, il, patriote, italiano, che, inneggiare, contro, il, rom, fare, il, spesa, a, il, <, Lidl, >, (, multinazionale, tedesco, ), .]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "6832               [il, stato, nazionale, dovere, essere, pronto, a, rinunciare, a, il, proprio, sovranità, ., lo, avere, dire, il, Merkel, ,, che, avere, aggiungere, che, il, stato, nazionale, non, dovere, ascoltare, il, volontà, di, il, loro, cittadino, quando, si, trattare, di, questione, che, riguardare, immigrazione, ,, confine, ,, o, persino, sovranità]   \n",
       "6833  [il, ministro, di, il, interno, di, il, Germania, <, Horst, Sehofer, >, ,, stare, fare, il, proposta, di, dare, soldo, a, il, immigrato, che, volere, tornare, a, casa, e, aiutare, li, a, creare, uno, attività, a, casa, loro, e, fare, business, con, il, Germania, ., chi, pagare, ?, uno, parte, il, crucco, e, il, resto, il, Europa, ,, cioè, io, e, voi, !]   \n",
       "6834                                            [<, Salvini, >, :, in, Italia, troppo, si, essere, montare, il, testa, ,, io, ringrazio, Dio, e, voi, per, questo, mese, straordinario, ., vi, raccontare, che, su, immigrazione, non, si, potere, fare, nulla, ,, essere, bastare, usare, buonsenso, e, coraggio, ., <, io, ci, essere, >, <, piazza, di, il, popolo, >]   \n",
       "6835                                                                                                          [chi, giubilare, in, buono, fede, non, avere, capire, niente, ., purtroppo, credere, che, il, più, non, essere, in, buono, fede, ., il, migrante, essere, uno, grosso, business, e, chi, finora, li, avere, volere, non, volere, perdere, questo, guadagno]   \n",
       "6836          [il, giovane, cristiano, in, <, Etiopia, >, essere, indurre, da, il, islamista, a, convertire, si, a, il, Islam, con, promessa, di, lavoro, ,, istruzione, e, aiuto, abitativo, ., alcuno, miniera, impiegare, solo, musulmano, ., lo, riferire, a, Acs, uno, leader, cristiano, locale, ,, anonimo, per, motivo, di, sicurezza, ., Preghare, per, loro, !]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                     pos  \\\n",
       "0                                                                                                                                                                                                                                        [AUX, NOUN, ADV, PRON, PUNCT, ADP, VERB, ADP, DET, NOUN, ADP, NOUN, DET, NOUN, CCONJ, VERB, DET, NOUN, PUNCT, SCONJ, PRON, PUNCT, PUNCT, PUNCT]   \n",
       "1                                                                                                                                                                                                                                                                  [ADV, SCONJ, PRON, AUX, VERB, ADP, DET, NOUN, SYM, NOUN, SYM, PRON, AUX, NOUN, ADP, SYM, PROPN, SYM, SYM, PROPN, SYM]   \n",
       "2                                                                                                                                                                                                                                                                                   [NOUN, PUNCT, PROPN, PUNCT, PROPN, PROPN, VERB, PROPN, ADP, NOUN, CCONJ, NOUN, NOUN, SYM, NOUN, SYM]   \n",
       "3                                                                                                                                                                                                                                                            [ADP, PRON, ADP, PRON, PUNCT, SCONJ, SCONJ, DET, NOUN, ADJ, VERB, ADP, NOUN, ADP, PROPN, VERB, ADV, DET, DET, PROPN, PUNCT]   \n",
       "4                                                                                                                                                                                                                        [DET, NOUN, ADP, DET, NOUN, PUNCT, VERB, DET, NOUN, ADJ, PRON, VERB, ADP, DET, NOUN, VERB, DET, NOUN, ADP, DET, SYM, PROPN, SYM, PUNCT, ADJ, ADJ, PUNCT, PUNCT]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                  ...   \n",
       "6832                                                                                            [DET, NOUN, ADJ, AUX, AUX, ADJ, ADP, VERB, ADP, DET, DET, NOUN, PUNCT, PRON, AUX, VERB, DET, PROPN, PUNCT, PRON, AUX, VERB, SCONJ, DET, NOUN, ADJ, ADV, AUX, VERB, DET, NOUN, ADP, DET, DET, NOUN, SCONJ, PRON, VERB, ADP, NOUN, PRON, VERB, NOUN, PUNCT, NOUN, PUNCT, CCONJ, ADV, NOUN]   \n",
       "6833  [DET, NOUN, ADP, DET, NOUN, ADP, DET, PROPN, SYM, PROPN, PROPN, SYM, PUNCT, AUX, VERB, DET, NOUN, ADP, VERB, NOUN, ADP, DET, NOUN, PRON, AUX, VERB, ADP, NOUN, CCONJ, VERB, PRON, ADP, VERB, DET, NOUN, ADP, NOUN, PRON, CCONJ, VERB, NOUN, ADP, DET, PROPN, PUNCT, PRON, VERB, PUNCT, DET, NOUN, DET, NOUN, CCONJ, DET, NOUN, DET, PROPN, PUNCT, CCONJ, PRON, CCONJ, PRON, PUNCT]   \n",
       "6834                                                                     [SYM, PROPN, SYM, PUNCT, ADP, PROPN, DET, PRON, AUX, VERB, DET, NOUN, PUNCT, PRON, VERB, NOUN, CCONJ, PRON, ADP, DET, NOUN, ADJ, PUNCT, PRON, VERB, SCONJ, ADP, NOUN, ADV, PRON, AUX, VERB, PRON, PUNCT, AUX, VERB, VERB, NOUN, CCONJ, NOUN, PUNCT, SYM, PRON, PRON, VERB, SYM, SYM, NOUN, ADP, DET, NOUN, SYM]   \n",
       "6835                                                                                                                                                                [PRON, VERB, ADP, ADJ, NOUN, ADV, AUX, VERB, PRON, PUNCT, ADV, VERB, SCONJ, DET, ADV, ADV, AUX, ADP, ADJ, NOUN, PUNCT, DET, NOUN, AUX, DET, ADJ, NOUN, CCONJ, PRON, ADV, PRON, AUX, VERB, ADV, AUX, VERB, DET, NOUN]   \n",
       "6836                                                                    [DET, NOUN, ADJ, ADP, SYM, PROPN, SYM, AUX, VERB, ADP, DET, NOUN, ADP, VERB, PRON, ADP, DET, PROPN, ADP, NOUN, ADP, NOUN, PUNCT, NOUN, CCONJ, NOUN, ADJ, PUNCT, DET, NOUN, VERB, ADV, NOUN, PUNCT, PRON, VERB, ADP, PROPN, DET, NOUN, ADJ, ADJ, PUNCT, ADJ, ADP, NOUN, ADP, NOUN, PUNCT, VERB, ADP, PRON, PUNCT]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                          dep  \\\n",
       "0                                                                                                                                                                                                                                           [cop, ROOT, advmod, nsubj, punct, mark, advcl, case, det, obl, case, nmod, det, obj, cc, conj, det, obj, punct, mark, advcl, punct, punct, punct]   \n",
       "1                                                                                                                                                                                                                                               [advmod, mark, obj, aux, advcl, case, det, obl, nmod, nmod, nmod, nsubj, cop, nmod, case, nmod, flat:name, nsubj, flat:name, flat:name, ROOT]   \n",
       "2                                                                                                                                                                                                                                                                          [nmod, punct, conj, punct, flat:name, flat:name, acl, flat:name, case, nmod, cc, conj, nmod, nmod, compound, ROOT]   \n",
       "3                                                                                                                                                                                                                                                   [case, ROOT, case, nmod, punct, mark, mark, det, nsubj, amod, advcl, case, obl, case, nmod, advcl, advmod, det:predet, det, nsubj, punct]   \n",
       "4                                                                                                                                                                                                         [det, ROOT, case, det, nmod, punct, ROOT, det, obj, amod, nsubj, acl:relcl, case, det, obl, advcl, det, obj, case, det, obl, flat:name, flat:name, punct, amod, amod, punct, punct]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "6832                                                                   [det, nsubj, amod, aux, cop, ROOT, mark, advcl, case, det, det:poss, obl, punct, obj, aux, ROOT, det, nsubj, punct, nsubj, aux, acl:relcl, mark, det, nsubj, amod, advmod, aux, ccomp, det, obj, case, det, det:poss, nmod, mark, expl, advcl, case, obl, nsubj, acl:relcl, obj, punct, conj, punct, cc, advmod, conj]   \n",
       "6833  [det, nsubj, case, det, nmod, case, det, nmod, nmod, flat:name, flat:name, flat:name, punct, aux, ROOT, det, obj, mark, acl, obj, case, det, obl, nsubj, aux, acl:relcl, case, obl, cc, conj, obj, mark, xcomp, det, obj, case, obl, nmod, cc, conj, obj, case, det, nmod, punct, nsubj, ROOT, punct, det, ROOT, det, nmod, cc, det, conj, det, nmod, punct, cc, conj, cc, conj, punct]   \n",
       "6834                                      [ROOT, flat:name, flat:name, punct, case, obl, nsubj, expl, aux, ROOT, det, obj, punct, nsubj, advcl, obj, cc, conj, case, det, obl, amod, punct, iobj, ROOT, mark, case, obl, advmod, expl:impers, aux, ccomp, obj, punct, aux, conj, xcomp, obj, cc, conj, punct, obl, nsubj, expl, ROOT, nsubj, flat:name, compound, case, det, nmod, flat:name]   \n",
       "6835                                                                                                                                            [nsubj, advcl, case, amod, obl, advmod, aux, ROOT, obj, punct, advmod, ROOT, mark, det, advmod, advmod, cop, case, amod, ccomp, punct, det, nsubj, cop, det, amod, ROOT, cc, nsubj, advmod, obj, aux, acl:relcl, advmod, aux, conj, det, obj]   \n",
       "6836                                           [det, nsubj:pass, amod, case, nmod, flat:name, flat:name, aux:pass, ROOT, case, det, obl, mark, xcomp, expl, case, det, obl, case, obl, case, nmod, punct, conj, cc, conj, amod, punct, det, nsubj, ROOT, advmod, obj, punct, obj, ROOT, case, obl, det, nsubj, amod, amod, punct, amod, case, obl, case, nmod, punct, ROOT, case, obl, punct]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        word_polarity  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                         [neutral, negative, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                     [neutral, neutral, neutral, negative, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                 [neutral, neutral, neutral, neutral, negative, neutral, neutral, neutral, neutral, negative, neutral, positive, neutral, neutral, neutral, neutral]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                    [neutral, positive, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral]   \n",
       "4                                                                                                                                                                                                                                                                                                                                       [neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...   \n",
       "6832                                                                                                                                     [neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, negative, negative, neutral, neutral, neutral, neutral, negative, neutral, neutral, neutral, neutral, neutral, None, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, negative, neutral, neutral, neutral, neutral]   \n",
       "6833  [neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, negative, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, positive, neutral, neutral, neutral, positive, neutral, neutral, positive, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral]   \n",
       "6834                                                                                                      [neutral, neutral, neutral, neutral, neutral, neutral, negative, neutral, neutral, neutral, neutral, positive, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, negative, neutral, neutral, neutral, None, neutral, neutral, neutral, negative, neutral, neutral, positive, neutral, positive, neutral, positive, neutral, neutral, positive, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral]   \n",
       "6835                                                                                                                                                                                                                                      [neutral, positive, neutral, positive, positive, None, negative, positive, negative, neutral, neutral, positive, neutral, neutral, neutral, None, neutral, neutral, positive, positive, neutral, neutral, neutral, neutral, positive, neutral, positive, neutral, neutral, neutral, neutral, negative, neutral, None, neutral, negative, neutral, positive]   \n",
       "6836                                                                                             [neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, negative, neutral, positive, neutral, neutral, neutral, positive, neutral, neutral, positive, positive, neutral, neutral, neutral, positive, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                              tokens  \\\n",
       "0                                                                                                                                                                                                                   [È, terrorismo, anche, questo, ,, per, mettere, in, uno, stato, di, soggezione, le, persone, e, renderle, innocue, ,, mentre, qualcuno, ., ., .]   \n",
       "1                                                                                                                                                                                                                                            [infatti, finché, ci, hanno, guadagnato, con, i, campi, <, rom, >, tutto, era, ok, con, <, Alemanno, >, <, Ipocriti, >]   \n",
       "2                                                                                                                                                                                                                                                           [Corriere, :, Tangenti, ,, Mafia, Capitale, dimenticata, Mazzette, su, buche, e, campi, rom, <, roma, >]   \n",
       "3                                                                                                                                                                                                                            [ad, uno, ad, uno, ,, perché, quando, i, migranti, israeliti, arrivarono, in, terra, di, Canaan, fecero, fuori, tutti, i, Canaaniti, .]   \n",
       "4                                                                                                                                                                                        [Il, divertimento, del, giorno, ?, Trovare, i, patrioti, italiani, che, inneggiano, contro, i, rom, facendo, la, spesa, alla, <, Lidl, >, (, multinazionale, tedesca, ), .]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                              ...   \n",
       "6832                     [Gli, stati, nazionali, devono, essere, pronti, a, rinunciare, alla, propria, sovranità, ., Lo, ha, detto, la, Merkel, ,, che, ha, aggiunto, che, gli, stati, nazionali, non, devono, ascoltare, la, volontà, dei, loro, cittadini, quando, si, tratta, di, questioni, che, riguardano, immigrazione, ,, confini, ,, o, persino, sovranità]   \n",
       "6833  [Il, ministro, dell', interno, della, Germania, <, Horst, Sehofer, >, ,, sta, facendo, la, proposta, di, dare, soldi, agli, immigrati, che, vogliono, tornare, a, casa, e, aiutarli, a, creare, un', attività, a, casa, loro, e, fare, business, con, la, Germania, ., Chi, paga, ?, Una, parte, i, crucchi, e, il, resto, l', Europa, ,, cioè, io, e, voi, !]   \n",
       "6834                                                  [<, Salvini, >, :, In, Italia, troppi, si, sono, montati, la, testa, ,, io, ringrazio, Dio, e, voi, per, questi, mesi, straordinari, ., Vi, raccontavano, che, su, immigrazione, non, si, poteva, fare, nulla, ,, è, bastato, usare, buonsenso, e, coraggio, ., <, io, ci, sono, >, <, piazza, del, popolo, >]   \n",
       "6835                                                                                                                      [Chi, giubila, in, buona, fede, non, ha, capito, niente, ., Purtroppo, credo, che, i, più, non, siano, in, buona, fede, ., I, migranti, sono, un, grosso, business, e, chi, finora, li, ha, voluti, non, vuole, perdere, questo, guadagno]   \n",
       "6836           [I, giovani, cristiani, in, <, Etiopia, >, sono, indotti, dagli, islamisti, a, convertirsi, all', Islam, con, promesse, di, lavoro, ,, istruzione, e, aiuti, abitativi, ., Alcune, miniere, impiegano, solo, musulmani, ., Lo, riferisce, ad, Acs, un, leader, cristiano, locale, ,, anonimo, per, motivi, di, sicurezza, ., Preghiamo, per, loro, !]   \n",
       "\n",
       "      %bad_words  \\\n",
       "0              0   \n",
       "1              0   \n",
       "2              0   \n",
       "3              0   \n",
       "4              0   \n",
       "...          ...   \n",
       "6832           0   \n",
       "6833           0   \n",
       "6834           0   \n",
       "6835           0   \n",
       "6836           0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                   stem  \n",
       "0                                                                                                                                                                                        [è, terror, anche, quest, ,, per, mett, in, uno, stat, di, soggezion, le, person, e, rend, innocu, ,, mentr, qualcun, ., ., .]  \n",
       "1                                                                                                                                                                                                            [infatt, finc, ci, hann, guadagn, con, i, camp, <, rom, >, tutt, era, ok, con, <, alemann, >, <, ipocr, >]  \n",
       "2                                                                                                                                                                                                                             [corr, :, tangent, ,, maf, capital, dimentic, mazzett, su, buch, e, camp, rom, <, rom, >]  \n",
       "3                                                                                                                                                                                                  [ad, uno, ad, uno, ,, perc, quand, i, migrant, israel, arriv, in, terr, di, canaan, fecer, fuor, tutt, i, canaan, .]  \n",
       "4                                                                                                                                                                   [il, divert, del, giorn, ?, trov, i, patriot, italian, che, innegg, contr, i, rom, fac, la, spes, alla, <, lidl, >, (, multinazional, tedesc, ), .]  \n",
       "...                                                                                                                                                                                                                                                                                                                 ...  \n",
       "6832                      [gli, stat, nazional, dev, esser, pront, a, rinunc, alla, propr, sovran, ., lo, ha, dett, la, merkel, ,, che, ha, aggiunt, che, gli, stat, nazional, non, dev, ascolt, la, volont, dei, lor, cittadin, quand, si, tratt, di, question, che, riguard, immigr, ,, confin, ,, o, persin, sovran]  \n",
       "6833  [il, ministr, dell', intern, dell, german, <, horst, sehofer, >, ,, sta, fac, la, propost, di, dar, sold, agli, immigr, che, vogl, torn, a, cas, e, aiut, a, cre, un', attiv, a, cas, lor, e, far, business, con, la, german, ., chi, pag, ?, una, part, i, crucc, e, il, rest, l', europ, ,, cio, io, e, voi, !]  \n",
       "6834                                             [<, salvin, >, :, in, ital, tropp, si, son, mont, la, test, ,, io, ringraz, dio, e, voi, per, quest, mes, straordinar, ., vi, raccont, che, su, immigr, non, si, pot, far, null, ,, è, bast, usar, buonsens, e, coragg, ., <, io, ci, son, >, <, piazz, del, popol, >]  \n",
       "6835                                                                                                  [chi, giubil, in, buon, fed, non, ha, cap, nient, ., purtropp, cred, che, i, più, non, sian, in, buon, fed, ., i, migrant, son, un, gross, business, e, chi, finor, li, ha, vol, non, vuol, perd, quest, guadagn]  \n",
       "6836                    [i, giovan, cristian, in, <, etiop, >, son, indott, dagl, islam, a, convert, all', islam, con, promess, di, lavor, ,, istruzion, e, aiut, abit, ., alcun, min, impieg, sol, musulman, ., lo, rifer, ad, acs, un, leader, crist, local, ,, anonim, per, mot, di, sicurezz, ., preg, per, lor, !]  \n",
       "\n",
       "[6837 rows x 16 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('new_modified_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
