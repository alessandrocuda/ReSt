{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fasttext\n",
    "#!rm -rf SaRaH/\n",
    "#!git clone https://github.com/alessandrocuda/SaRaH\n",
    "#!wget http://www.italianlp.it/twitter128.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "#from tensorflow.keras.engine import Layer, InputSpec, InputLayer\n",
    "\n",
    "#models\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "#layers\n",
    "from tensorflow.keras.layers import Dropout, Embedding, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Conv2D, MaxPool2D, ZeroPadding1D, GlobalMaxPool1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Concatenate, Dot, Concatenate, Multiply, RepeatVector\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Lambda, Permute\n",
    "#training\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#model_selection_evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "#word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath\n",
    "#import fasttext.util\n",
    "\n",
    "#utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "#src\n",
    "#root_project = \"/content/SaRaH/\"\n",
    "root_project = \"/Users/Alessandro/Dev/repos/SaRaH/\"\n",
    "#root_project = \"/home/jupyter/SaRaH/\"\n",
    "sys.path.append(root_project)\n",
    "from src.data.utils import load_csv_to_dict, string_to_list, set_unkmark\n",
    "from src.features.word_embedding import get_index_key_association, get_int_seq, build_keras_embedding_matrix, get_data_to_emb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.4.1\n",
      "GPU device not found\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version: {}\".format(tf.__version__))\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    print('GPU device not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dev_path           = root_project + \"dataset/haspeede2/preprocessed2/dev/dev.csv\"\n",
    "dataset_test_tweets_path   = root_project + \"dataset/haspeede2/preprocessed2/reference/reference_tweets.csv\"\n",
    "w2v_path                   = root_project + \"results/model/word2vec/word2vec2.wordvectors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load w2v and data\n",
    "w2v = KeyedVectors.load(w2v_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
