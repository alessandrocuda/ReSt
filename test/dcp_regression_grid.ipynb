{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dcp_regression_grid.ipynb","private_outputs":true,"provenance":[{"file_id":"1I8smkfcpLzk_3-klfmCwBlug7O25W7l2","timestamp":1613942404227}],"collapsed_sections":[],"authorship_tag":"ABX9TyNicYi8jcfSl+hB9F4eGuyw"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"XuBTEiXf-dXp"},"source":["!pip install tensorflow-addons"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxNQX3zXizwn"},"source":["import pandas as pd\n","import numpy as np\n","from itertools import product, chain\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","\n","from tensorflow.keras import backend as K\n","\n","\n","from tensorflow.keras.models import Model, Sequential\n","\n","from tensorflow.keras.layers import Dropout, concatenate\n","from tensorflow.keras.layers import Dense, Input, Flatten, BatchNormalization, Activation\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.models import load_model\n","from keras.wrappers.scikit_learn import KerasRegressor\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, f1_score\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import KFold\n","\n","#sklearn\n","from sklearn.decomposition import PCA\n","\n","#plot\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","from mpl_toolkits.mplot3d import Axes3D\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rDHj66-ji2f"},"source":["def dtype(dict_dataset):\n","    for k in dict_dataset.keys():\n","        print(\"{} {}\".format(k.ljust(60), type(dict_dataset[k][0])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l6LGU1eEjGPf"},"source":["dataset_path = \"/content/pazienti_completa.csv\"\n","dataset = pd.read_csv(dataset_path, sep=';').to_dict('list')\n","dtype(dataset)\n","dataset_shape = (len(dataset[\"Nome Pazienti\"]), len(dataset.keys()))\n","print()\n","print(\"Dataset shape: {}\".format(dataset_shape))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vF108lIzk69I"},"source":["features_list = [\"Coppia centrale assente\",                                     \n","                 \"Coppia centrale aggiuntiva\",                                   \n","                 \"Microtubulo centrale assente\",                                 \n","                 \"Microtubulo centrale aggiuntivo\",                              \n","                 \"Dislocazione coppia centrale %\",                               \n","                 \"Assenza central sheat %\",                                      \n","                 \"ODA+IDA\",                                                      \n","                 \"ODA\",                                                          \n","                 \"IDA\",                                                          \n","                 \"Assonemi a normale ultrastruttura %\"\n","]\n","targets       = [\"Movimento (%) scarsa escursione su campi tot\",\n","                \"Movimento (%) circolari su campi tot\",\n","                \"Movimento (%) mobili non patologiche\",\n","                \"Movimento (%) immobili / virtualmente immobili\"\n","]\n","\n","X = np.array([ dataset[feature] for feature in features_list]).T\n","y = np.array([ np.array(dataset[target])/100 for target in targets]).T\n","print(X.shape)\n","print(y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MAc4n1iRmwZz"},"source":["#example:\n","print(X[1])\n","print(y[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9eNdVT-f5inp"},"source":["# NN"]},{"cell_type":"code","metadata":{"id":"IosVeMPxybmD"},"source":["class ReturnBestEarlyStopping(EarlyStopping):\n","    def __init__(self, **kwargs):\n","        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n","\n","    def on_train_end(self, logs=None):\n","        if self.stopped_epoch > 0:\n","            if self.verbose > 0:\n","                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n","        elif self.restore_best_weights:\n","            if self.verbose > 0:\n","                print('Restoring model weights from the end of the best epoch.')\n","            self.model.set_weights(self.best_weights)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z19eyegn651f"},"source":["def create_model(hidden_first, hidden_second, regularizer, learning_rate, momentum, nesterov):\n","  # create model\n","  model = Sequential()\n","  model.add(Dense(hidden_first, input_dim=10, activation='sigmoid', kernel_regularizer=l2(regularizer)))\n","  model.add(Dense(hidden_second, activation='sigmoid', kernel_regularizer=l2(regularizer)))\n","  model.add(Dense(4, activation='sigmoid'))\n","\t# Compile model\n","  optimizer = SGD(learning_rate=learning_rate, momentum=momentum, nesterov=nesterov)\n","  metrics=['accuracy', tfa.metrics.RSquare(multioutput='uniform_average',dtype=tf.float32, y_shape=(4,))]\n","  model.compile(loss='MeanSquaredError', optimizer=optimizer)\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FVZNW6HQ7LGK"},"source":["best_callback = ReturnBestEarlyStopping(monitor=\"val_loss\", min_delta=0, patience=200, verbose=0, mode=\"min\", restore_best_weights=True)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=128)\n","#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=128)\n","model = create_model(64, 32, 0.0001, 0.001, 0.8, True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIbZLqO67Ncv"},"source":["history = model.fit(X_train, y_train, batch_size=32, epochs=2000, validation_data=(X_val, y_val), callbacks=[best_callback], verbose = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"85jsEdsOsLjw"},"source":["# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","# load dataset\n","# create model\n","model = KerasRegressor(build_fn=create_model, verbose=0)\n","# define the grid search parameters\n","param_grid = {\"hidden_first\":  [ 10], \n","              \"hidden_second\": [10], \n","              \"regularizer\":   [0.1], \n","              \"learning_rate\": [0.1], \n","              \"momentum\":      [0.1], \n","              \"nesterov\":      [False, True],\n","              \"epochs\":        [3],\n","              \"batch_size\":    [32]\n","}\n","\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5, verbose=1)\n","grid_result = grid.fit(X_train, y_train, validation_split=0.1, callbacks=[best_callback])\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KsHPJJY5tnmD"},"source":["grid_result.cv_results_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-T8eVfSr8dEz"},"source":["print(history.history.keys())\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"52vksqKS9Dmm"},"source":["model.evaluate(X_val, y_val)\n","model.evaluate(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hkDg3B_zAwBf"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import LogNorm\n","from sklearn import mixture\n","\n","\n","# fit a Gaussian Mixture Model with two components\n","clf = mixture.GaussianMixture(n_components=3, covariance_type='full')\n","clf.fit(X_reduced[:,:2])\n","\n","# display predicted scores by the model as a contour plot\n","x = np.linspace(-60., 70.)\n","y = np.linspace(-60., 70.)\n","X, Y = np.meshgrid(x, y)\n","XX = np.array([X.ravel(), Y.ravel()]).T\n","Z = -clf.score_samples(XX)\n","Z = Z.reshape(X.shape)\n","\n","CS = plt.contour(X, Y, Z, norm=LogNorm(vmin=1.0, vmax=1000.0), levels=np.logspace(0, 3, 10))\n","CB = plt.colorbar(CS, shrink=0.8, extend='both')\n","plt.scatter(X_reduced[:,0], X_reduced[:,1], 12, marker='o')\n","\n","plt.title('Negative log-likelihood predicted by a GMM')\n","plt.axis('tight')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9APxiEmg6EH"},"source":["X_reduced[:,:2].shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x8XoyjNc3PvA"},"source":["test2"]},{"cell_type":"code","metadata":{"id":"FNKplw7IjT3B"},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=128)\n","kf = KFold(n_splits=5, random_state=128, shuffle=True)\n","kfold_index = kf.split(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ELG6w24L6h9Z"},"source":["def product_dict(**kwargs):\n","    keys = kwargs.keys()\n","    vals = kwargs.values()\n","    for instance in product(*vals):\n","        yield dict(zip(keys, instance))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7pYY9D5t4YD9"},"source":["def nn_model(hidden_first, hidden_second, regularizer, learning_rate, momentum, nesterov):\n","  # create model\n","  model = Sequential()\n","  model.add(Dense(hidden_first, input_dim=10, activation='sigmoid', kernel_regularizer=l2(regularizer)))\n","  model.add(Dense(hidden_second, activation='sigmoid', kernel_regularizer=l2(regularizer)))\n","  model.add(Dense(4, activation='sigmoid'))\n","\t# Compile model\n","  optimizer = SGD(learning_rate=learning_rate, momentum=momentum, nesterov=nesterov)\n","  metrics=['accuracy', tfa.metrics.RSquare(multioutput='uniform_average',dtype=tf.float32, y_shape=(4,))]\n","  model.compile(loss='MeanSquaredError', optimizer=optimizer)\n","  return model\n","\n","\n","param_grid_dict = {\"hidden_first\":  [10,  30, 60, 150, 200, 300, 500, 1000], \n","                   \"hidden_second\": [10, 30, 60, 150, 200, 300, 500, 1000], \n","                   \"regularizer\":   [0.1, 0.001, 0.0001, 0.00001], \n","                   \"learning_rate\": [0.1, 0.01, 0.001, 0.0001], \n","                   \"momentum\":      [0.1, 0.2, 0.3, 0.4, 0.6, 0.7, 0.8], \n","                   \"nesterov\":      [False, True],          \n","}\n","\n","param_grid = list(product_dict(**param_grid_dict))\n","param_grid[0]\n","for hyper_param in param_grid:\n","  print(\"Start Grid Combination n.\")\n","  for train_index_fold, val_index_fold in kfold_index:\n","    X_trainf = X_train[train_index_fold]\n","    Y_trainf = y_train[train_index_fold]\n","\n","    X_valf = X_train[val_index_fold]\n","    Y_valf = y_train[val_index_fold]\n","    print(hyper_param)\n","    model = nn_model(**hyper_param)\n","    history = model.fit(X_trainf, Y_trainf, batch_size=32, epochs=2000, validation_data=(X_valf, Y_valf), callbacks=[best_callback], verbose = 0)\n","    model.evaluate(X_trainf, Y_trainf)\n","    model.evaluate(X_valf, Y_valf)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2gtrG5tRzSHF"},"source":[""],"execution_count":null,"outputs":[]}]}